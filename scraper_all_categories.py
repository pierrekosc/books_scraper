"""
Script de scraping pour extraire les informations de toutes les cat√©gories de livres
sur Books to Scrape et les enregistrer dans des fichiers CSV distincts.

Ce script fonctionne de mani√®re modulaire et repose sur l'utilisation des fonctions
suivantes :

- `get_category_urls()`: R√©cup√®re toutes les URLs des cat√©gories du site.
- `scrape_category(category_url, output_filename)`: Scrape tous les livres d'une cat√©gorie et sauvegarde les donn√©es dans un fichier CSV.

L'objectif est d'extraire les donn√©es de toutes les cat√©gories disponibles sur le site,
chaque cat√©gorie ayant son propre fichier CSV de sortie.
"""

import requests
from bs4 import BeautifulSoup
import os
from scraper_category import scrape_category
from scraper_single import scrape_book_data
from scraper_url_livres import get_books_urls

BASE_URL = "https://books.toscrape.com/"


def get_categories():
    """R√©cup√®re toutes les cat√©gories du site avec leurs URLs, en ignorant la premi√®re (Books)."""
    response = requests.get(BASE_URL)
    response.raise_for_status()
    soup = BeautifulSoup(response.text, 'html.parser')

    categories = {}
    
    # S√©lectionner tous les liens des cat√©gories et ignorer le premier (Books)
    category_links = soup.select(".side_categories ul li a")[1:]

    for link in category_links:
        category_name = link.text.strip()
        category_url = BASE_URL + link["href"]
        categories[category_name] = category_url

    return categories


def scrape_full_site():
    """Scrape tout le site Books to Scrape en r√©cup√©rant chaque cat√©gorie."""
    categories = get_categories()  # R√©cup√®re toutes les cat√©gories disponibles

    for category_name, category_url in categories.items():
        print(f"üìÇ Scraping la cat√©gorie : {category_name} ...")

        # D√©finir un nom de fichier CSV unique pour chaque cat√©gorie
        csv_filename = f"output/{category_name.replace(' ', '_').lower()}.csv"

        # Scraper la cat√©gorie et enregistrer les donn√©es
        scrape_category(category_url, csv_filename)

    print("Tous les livres du site ont √©t√© scrapp√©s avec succ√®s !")


# Lancer le scraper
if __name__ == "__main__":
    scrape_full_site()
